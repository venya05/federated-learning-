{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO75MA0J1DKS7BW0QSwltJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeZKjbulH3zf",
        "outputId": "faf731b4-9bcd-4ab7-8c66-2f7e2438ec59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.7/531.7 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.0/87.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.common import Context\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets import FederatedDataset\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bbBeL51IiUf",
        "outputId": "5ebb12a1-db3e-4fe5-a206-aa172d295aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Flower 1.15.2 / PyTorch 2.5.1+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_datasets(partition_id: int, num_partitions: int):\n",
        "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
        "    partition = fds.load_partition(partition_id)\n",
        "    # Divide data on each node: 80% train, 20% test\n",
        "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
        "    pytorch_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "\n",
        "    def apply_transforms(batch):\n",
        "        # Instead of passing transforms to CIFAR10(..., transform=transform)\n",
        "        # we will use this function to dataset.with_transform(apply_transforms)\n",
        "        # The transforms object is exactly the same\n",
        "        batch[\"img\"] = [pytorch_transforms(img) for img in batch[\"img\"]]\n",
        "        return batch\n",
        "\n",
        "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
        "    trainloader = DataLoader(partition_train_test[\"train\"], batch_size=32, shuffle=True)\n",
        "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=32)\n",
        "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
        "    testloader = DataLoader(testset, batch_size=32)\n",
        "    return trainloader, valloader, testloader"
      ],
      "metadata": {
        "id": "NQuWRWFsIjha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"img\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images, labels = batch[\"img\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "0gpbYDFKIt81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerNumPyClient(NumPyClient):\n",
        "    def __init__(self, partition_id, net, trainloader, valloader):\n",
        "        self.partition_id = partition_id\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "KTYZaWdWIxXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def numpyclient_fn(context: Context) -> Client:\n",
        "    net = Net().to(DEVICE)\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    num_partitions = context.node_config[\"num-partitions\"]\n",
        "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
        "    return FlowerNumPyClient(partition_id, net, trainloader, valloader).to_client()\n",
        "\n",
        "\n",
        "# Create the ClientApp\n",
        "numpyclient = ClientApp(client_fn=numpyclient_fn)"
      ],
      "metadata": {
        "id": "IX26_d3HI1UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    # Configure the server for 3 rounds of training\n",
        "    config = ServerConfig(num_rounds=3)\n",
        "    return ServerAppComponents(config=config)\n",
        "\n",
        "\n",
        "# Create ServerApp\n",
        "server = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "iE1iPiTbL3QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the resources each of your clients need\n",
        "# If set to none, by default, each client will be allocated 2x CPU and 0x GPUs\n",
        "backend_config = {\"client_resources\": None}\n",
        "if DEVICE.type == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_gpus\": 1}}\n",
        "\n",
        "NUM_PARTITIONS = 10\n",
        "\n",
        "# Run simulation\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=numpyclient,\n",
        "    num_supernodes=NUM_PARTITIONS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_khDZS3DMU5O",
        "outputId": "001bcc9f-eced-47ba-f436-7a009298c2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:Asyncio event loop already running.\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=5306)\u001b[0m 2025-02-22 05:46:47.553593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=5306)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=5306)\u001b[0m E0000 00:00:1740203207.578931    5306 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=5306)\u001b[0m E0000 00:00:1740203207.586615    5306 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m /usr/local/lib/python3.11/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "Generating train split:   0%|          | 0/50000 [00:00<?, ? examples/s]\n",
            "Generating train split:   8%|▊         | 4000/50000 [00:00<00:01, 29024.27 examples/s]\n",
            "Generating train split:  21%|██        | 10500/50000 [00:00<00:00, 46888.20 examples/s]\n",
            "Generating train split:  34%|███▎      | 16800/50000 [00:00<00:00, 53288.29 examples/s]\n",
            "Generating train split:  47%|████▋     | 23400/50000 [00:00<00:00, 57809.94 examples/s]\n",
            "Generating train split:  62%|██████▏   | 31100/50000 [00:00<00:00, 64330.43 examples/s]\n",
            "Generating train split:  79%|███████▉  | 39500/50000 [00:00<00:00, 70372.70 examples/s]\n",
            "Generating train split: 100%|██████████| 50000/50000 [00:00<00:00, 63365.26 examples/s]\n",
            "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]\n",
            "Generating test split:  82%|████████▏ | 8200/10000 [00:00<00:00, 80555.60 examples/s]\n",
            "Generating test split: 100%|██████████| 10000/10000 [00:00<00:00, 77886.92 examples/s]\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 9] get_parameters\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.0653839260339737, accuracy 0.22575\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.06534437090158463, accuracy 0.221\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.06539936363697052, accuracy 0.217\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.06659355759620667, accuracy 0.189\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.06565361469984055, accuracy 0.22225\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.06535127758979797, accuracy 0.228\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.06546255201101303, accuracy 0.2175\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.06527777016162872, accuracy 0.23625\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.06594972312450409, accuracy 0.20825\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 8] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.0658802017569542, accuracy 0.216\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.05916011705994606, accuracy 0.298\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.059411369264125824, accuracy 0.3005\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.058530550450086594, accuracy 0.31275\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.05922050029039383, accuracy 0.3115\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.05846981331706047, accuracy 0.30625\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.0589534267783165, accuracy 0.30825\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.05826903507113457, accuracy 0.31375\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.058544695377349854, accuracy 0.32175\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.058911293745040894, accuracy 0.30225\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 5] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.059198152273893356, accuracy 0.28225\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.0550396591424942, accuracy 0.355\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.054933782666921616, accuracy 0.349\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.0546678751707077, accuracy 0.36675\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.05343230068683624, accuracy 0.3635\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.05440385639667511, accuracy 0.3515\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.05437876284122467, accuracy 0.3705\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.0554819218814373, accuracy 0.334\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.054622817784547806, accuracy 0.35725\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.054920658469200134, accuracy 0.352\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 3] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m Epoch 1: train loss 0.05374069884419441, accuracy 0.374\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 7] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[36m(ClientAppActor pid=5306)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 384.09s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.063454574406147\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.05613302038908006\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.052657102560997\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_global_model(net, testloader):\n",
        "    \"\"\"Evaluate the global model on the test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for batch in testloader:\n",
        "            images, labels = batch[\"img\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy\n"
      ],
      "metadata": {
        "id": "nAyKVI3tYd6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_after_training(global_model: nn.Module):\n",
        "    \"\"\"Evaluate the model after federated training.\"\"\"\n",
        "    # Load the global test dataset\n",
        "    testset = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": 1})\n",
        "    testset = testset.load_split(\"test\")\n",
        "    testloader = DataLoader(testset, batch_size=32)\n",
        "\n",
        "    # Evaluate the final model\n",
        "    loss, accuracy = evaluate_global_model(global_model, testloader)\n",
        "    print(f\"Final Model Test Loss: {loss}\")\n",
        "    print(f\"Final Model Test Accuracy: {accuracy * 100}%\")\n"
      ],
      "metadata": {
        "id": "SRnmDWAdYev6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_transforms(batch):\n",
        "    # Apply transformations to the images in the batch\n",
        "    batch[\"img\"] = [transforms.ToTensor()(img) for img in batch[\"img\"]]  # Ensure conversion to Tensor\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "9YuNrfAtY0Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_datasets(partition_id: int, num_partitions: int):\n",
        "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": num_partitions})\n",
        "    partition = fds.load_partition(partition_id)\n",
        "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "    # Ensure the transformations are applied to the images\n",
        "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
        "\n",
        "    # Rest of the code...\n"
      ],
      "metadata": {
        "id": "aHmeinwAY4Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "puprkPCaYkXD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}